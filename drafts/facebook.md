---
title: Facebook, Badges, and the Hyperreal
date: 2020-06-13
---

## Intro
One of the things recently that's been on my mind is social networks and their
effects. I think social networks are vastly important and outside of strict CS
network theory I don't see as many studies as I'd like about them. I feel this
should eventually form a more coherent thought process but for now I'm just
going to spew it out and later come back and edit. For refernece my ideas are a
synthesis derived from [this
article](https://www.theatlantic.com/magazine/archive/2020/06/qanon-nothing-can-stop-what-is-coming/610567/)
and this [lecture](http://timroughgarden.org/f16/l/l6.pdf). And the question I
want to ask is 

## A Question

>
> Why is Facebook such a breeding ground for bad stuff?
>

You might notice how vauge this is. And it's vauge on purpose. Initially I
wanted to talk about truthfulness and develop some sort of algorithm to
determine the truthfulness of things. The problems with such an idea are
manyfold.

1. Truthfulness algorithms would inhereit the same biases we as people employ
2. Truth is not attainable*

For now I'm treating these as axioms but I definitely should develop these
further in the future. My reasoning for the first one is a direct descedent of
problems in machine learning. Our final algorithm is going to be biased to the
input data its fed.  The second point took me a long time to get-around to
accepting but I think I've finally got it. I want to say first and foremost if
the world were split into ["fuzzy" and
"techie"](https://undergrad.stanford.edu/events/fuzzy-and-techie-false-divide)
,lets just say it is, then I'm ultimately a "techie". I've tried being "fuzzie"
and I can pass but it's not in my DNA. That's okay. The world needs both.  My
point with this though is that I'm a strong believer in science and the hunt
for truth. I was that cringey kid in middleschool who posted [Dawkins quote on
Instagram](https://web.archive.org/web/20200618212334/https://slatestarcodex.com/2019/10/30/new-atheism-the-godlessness-that-failed/)
That said recently some friends have convinced me that truth is not an
attainable thing. I'm still having trouble wrapping my head around it and I'm
not fully convinced but I welcome any ideas challenging my own.  There's a lot
that can be said about the construction of truth and wether it's tied with our
physiological understanding, or how truth relates to the
[hyperreal](https://plato.stanford.edu/entries/baudrillard/) but actually none
of that is what's helped convince me that truth is perhaps not attainable. 

In fact, oddly enough, it was [**Pizza Gate**](https://en.wikipedia.org/wiki/Pizzagate_conspiracy_theory) The most
insane thing is I actually remember browsing **/r/T_D** back when they were
forming this theory and I was thinking no way. I'm sure you can find the post
now somewhere on the internet archive but I vaguaely remember them relating the
signage to some pedophilia ring...

I don't want to dwell on the details of it too much. It seems when ever the
internet spills over into reality bad things happen. However, the point is
everyone involved or believes in **Pizza Gate** believes it is the truth.
Before talking with my friend I coud *buy* the argument that people involved in
**Pizza Gate** perhaps believed it's true but once it all went down surely all
the possibility realites collaped and the truth made it out. Surely right?  And
yet I couldn't be more wrong. The reality, or I should say our reality, didn't
really affect those who believed in it. What's more is all rhetorical tools we
perform science with the research, the facts, the evidence, etc. those same
tools are used by these believers. That's what makes them so convinced. They're
essentially conducting their own bad science experiments. So the quandry I
faced was I don't really have a good algorithmic mechanism for discerning my
truth from their *truth* besides like a gut feeling that it's an obvious case
of [occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor) even then I'm
not sure that'd hold up in formal verification. So that's where I currently am
in my thinking kinda stuck in a rut between the world I love and know and
somehow having to fit these other-truthers into the model. I'm sure a lot of
people would wave them off as crazies, we can't listen to them, and generally
disregard them.  However, I don't think this is a good solution either. Their
sentiment and distrust of the way things are actually mimicked in a lot of
leftist circles. I can't really cite specific cases right now but just take the
general case of distrusting the government and its easy to see how to paths
evolve from there. And honestly, I kinda totally get it. Take all the latest
craze about **5G**. It does sound a little ominous at face value doesn't?  And
I do find the memes about it really funny but I feel privileged enough to have
been given the tools to understand the *modern* world around me. But I could
totally relate to seeing things go to fast and say wait a minute, hold up
**WHAT‽**

Okay there's more I want to say here but I have to move on to the crux of this.


## The Entrée 

So I do want to develop this more but on the high chance I don't I want to get what I have currently cooked up out. 

So what's the problem with Facebook? Lots of people have said lots of things I'm sure, but let me give you my hot take. This is the entrée after all.
Facebook has abysmal content moderation. Like practically non-existent. So what do I mean here. I feel there's two kinds of content-moderation

1. Human admins
2. The consumers

It definitely would not kill me to make those better terms but you get the
idea. When we talk about online formums human admins are the weird people who
just moderate, who knows why. They often have cool special badges (more on
this later) and they are the moral arbitrers of what content gets to be
discussed etc. These generally should be avoided for the same reason we should
avoid facists or family reunions with strong patriarchs. Even in your online
forum about gardening the power can go to the head of mods. There aren't a lot
of great mechanisms right now for removing rouge mods. The most common is you
go to the **SUPER USER** and you go hey this mod is abusing their privileges
and then you honestly hope that the admins have mercy on you and take care of
it. Admins are incentivized to help you because they usually have a real
interest (real == finacial) in the success of the platform and so they want as
many users as possible. Admins more or less are benevolent, as its in their
best interest.
[Here]("https://www.reddit.com/r/announcements/comments/5frg1n/tifu_by_editing_some_comments_and_creating_an/")
you can see what happens. When this happened it was huge I remember **/r/TD**
calling for */u/spez* to step down and encroachment of their freedom of speech.
The thing is, on the internet as long as we're transacting through private
platforms we're really subject to their TOS. 

So yes human moderators can be evil. [But they also can be good](https://www.vice.com/en_us/article/avyjkz/virgil-texas-white-power-facebook-group-troll).
They post announcements and teams of them make important decisions and they
generally keep forums very nice. They're grounds keepers for communities Reddit
is cool because a lot of moderators can be bots that perform automated helpful
tasks.  When you find a bot that's useful you can even say "good bot" and then
[another bot comes](https://www.reddit.com/user/goodbot_badbot) around and
keeps score, like a digital dog treat. 

Anyways the point is moderators are probably a necessary evil to online forums.
Going back to the design of facebook they're are moderators but their positions
aren't well incentivized.  If you're in a facebook group its the job of the
moderator to control posts and stuff and keep everything on topic but for all
the work they do they get to pin posts and get a little tag. Furthermore, they
don't even get robot slaves to do a lot of the menial work for them. This leads
to poor group interactions on Facebook and it's the reason that people don't
really use Facebook for more informationy things like they do
dedicated-forums. And you know what, I think Facebook is okay with that so
that's why they haven't put a lot of work into group moderation. When I go to a
facebook group I have a feeling like I'm in that part of the Percy Jackson
books where he goes into a casino and they try and keep him forever. I feel so
disoriented with all the out of order posting. 

Okay so I think we all agree upon how moderators are driven by incentives to do
a good job moderating. However there's another part to moderating that's even
more important. Designated moderators (and admins) should function like a
safety-net and only step in when necessary and maintain a nice community. The
more important moderators on internet forums are the people themselves. A good
internet forum gives people the power to police themselves and form complex
organizations. In the following bit I want to compare and contrast how various
online forums hande this.

### Reddit 

Reddit I think does a fairly good job of self-moderation. The main
system is upvotes and downvotes. Most posts you see have sum net upvote
count
[Here](https://github.com/reddit-archive/reddit/blob/bd922104b971a5c6794b199f364a06fdf61359a2/r2/r2/lib/db/_sorts.pyx#L47)
is a link to the following algorithm for hot

```python
cpdef double _hot(long ups, long downs, double date):
"""The hot formula. Should match the equivalent function in postgres."""
s = score(ups, downs) 
order = log10(max(abs(s), 1)) 
if s > 0: 
    sign = 1
elif s < 0:
    sign = -1 
else:
    sign = 0
seconds = date - 1134028003 #Time minus 
return round(sign * order + seconds / 45000, 7)
```

It takes the score of the post and retruns its rank according to 3 criteria:

1. The logarithm normalizes everything to account for one can be called the
acceleration of the upvotes. The link in the bottom explains it better but
essentially a score of 3000 will be 2000 greater than a score of 1000.
However, it shouldn't because of how hard marginal votes are to get. So
really the difference between 3000 and 1000 should be more like the
difference between 30 and 10. When in doubt with things like this take the
ln to normalize the graph. If the ln doesn't work you're screwed.

ahhhhh update. I realized that there are actually 3 main reddit ranking
algorithms
1. Time delay 
2. absoluute
3. Weighted rank ie lower bound of wilson score confidence interval for a
   bernoulli parameter

And these are all great truly. But the beauty of Reddit\'s ranking algorithm
is it's simplicity. It's a very clear yin-yang between upvote and downvote.
It's a good natural system and gives freedom of choice to the ranking
algorithm to the user.



For a better overiew than me on this subject
[see](https://www.evanmiller.org/how-not-to-sort-by-average-rating.html)
and
[here](https://medium.com/hacking-and-gonzo/how-reddit-ranking-algorithms-work-ef111e33d0d9)
and 
[here](https://redditblog.com/2009/10/15/reddits-new-comment-sorting-system/)



### Stack Exchange
    
I\'d say stack exchange is probably the best but that's just because I
program and stackoverflow exists. However, what I can say overall about
stack exchange 

One noticeable UI element is how all the comments are on the same level.
This UI forces comments to happen in a single thread instead of branching
off. Also the size of comments relative to the main response denotes them as
subsidiaries. Compare this to reddit where everything is on the same level. 

### Facebook

 So this is like a case study in how not to do a good job with the tools for self moderation.

 One thing that really bothers me is the angry react. Facebook is such a big
 community with no such thing as a [redditquie]() nor control over it's users 
 like
 [stack](https://stackoverflow.blog/2018/04/26/stack-overflow-isnt-very-welcoming-its-time-for-that-to-change/)



#### Twiter

Threads are the dumbest fucking thing ever
