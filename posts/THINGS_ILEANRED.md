# Things I learned 6/14/2020
So one really cool thing that I've always wondered about was
branch prediction and how it works. I thought there was some crazy
amazing algorithm that made it work.
Turns out doing what we did last time works 85% of the time...

That's not to say that there isn't a crazy amazing algorithm as well. According
to Jim Keller the current implementation of branch prediction which achieves at
least 95% accuracy (I forget the exact number) anyways that uses some
rudimentary form of deep learning that they've somehow packed into 10MB. Amazing



# THINGS I learnd 6/15/2020
https://meta.stackexchange.com/questions/2950/should-hi-thanks-taglines-and-salutations-be-removed-from-posts/93989#93989

# Things I leanred 6/23/2020 
One thing I've always been confused about is why have a codomain, image,
preimage, range, domain for all seemingly related things. Here I'll explain it,
the terms range,image, codomain are similar but have nuanced differences. The
way it was recently explained to me that made a lot of sense was that mappings
can be considered as having two parts an onto and an into part. 

The domain to the codomain is an into part where the domain maps into the
codomain. Then the codomain maps onto the image (also known as the range)
This makes sense if you think about it because the image is a subset of the
codomain. 

If we think about this in vector spaces the domain maps to a subspace of the
codomain vector space which is then the image. It's just so beautiful now that I
write it out. 

# Things I leanred 6/24/2020 
Hedge funds pay for flight patterns of private jets in the US to try and predict
mergers and acquisitions 
